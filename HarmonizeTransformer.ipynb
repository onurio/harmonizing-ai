{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nhzT_Fm--EYR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/95/0csrhky965x_1zggpg7jfkr00000gn/T/ipykernel_44131/3752955255.py:3: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from model import MusicTransformer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-KP7nUUCA3Jh"
      },
      "outputs": [],
      "source": [
        "chords = pd.read_csv(\"output_chords.csv\", header=None)\n",
        "# chords.head\n",
        "\n",
        "chords_sorted = chords.apply(lambda x: sorted(x), axis=1)\n",
        "\n",
        "# Drop duplicates to get unique chords\n",
        "# Count the unique chords\n",
        "# vocab_size = len(chords_sorted.drop_duplicates())\n",
        "# print(\"Vocabulary Size (Unique Chords):\", vocab_size)\n",
        "# # vocab is 10950 for /content/output_chords.csv\n",
        "vocab_size = 10950\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5aUD9EwiHDxf"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "\n",
        "batch_size=128\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('output_chords.csv')\n",
        "\n",
        "def create_sequences(dataset, sequence_length=4):\n",
        "    input_sequences = []\n",
        "    output_notes = []\n",
        "\n",
        "    for i in range(round(len(dataset)*1 - sequence_length)):\n",
        "        sequence = dataset[i:i + sequence_length].values.tolist()\n",
        "\n",
        "        # Selecting 2 random notes from the 4th chord\n",
        "        fourth_chord = sequence[-1]\n",
        "        output = random.sample(fourth_chord, 2)\n",
        "\n",
        "        # Removing the selected notes from the 4th chord in the input\n",
        "        for note in output:\n",
        "            fourth_chord.remove(note)\n",
        "\n",
        "        input_sequences.append(sequence)\n",
        "        output_notes.append(output)\n",
        "\n",
        "    return input_sequences, output_notes\n",
        "\n",
        "# Create input-output pairs\n",
        "input_sequences, output_notes = create_sequences(dataset)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(input_sequences, output_notes, test_size=0.2, random_state=42,shuffle=False)\n",
        "\n",
        "# Preparing PyTorch dataset\n",
        "class ChordDataset(Dataset):\n",
        "    def __init__(self, sequences, labels):\n",
        "        self.sequences = sequences\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Prepare the input sequence as a 4x3 matrix\n",
        "        sequence_matrix = []\n",
        "        for chord in self.sequences[idx]:\n",
        "            # Pad the chord with zeros if less than 3 notes\n",
        "            padded_chord = chord + [0] * (3 - len(chord))\n",
        "            sequence_matrix.append(padded_chord)\n",
        "\n",
        "        return {\n",
        "            'sequence': torch.tensor(sequence_matrix, dtype=torch.long),\n",
        "            'label': torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "        }\n",
        "\n",
        "# Adjust the create_sequences function if needed to ensure correct formatting\n",
        "\n",
        "\n",
        "# Creating data loaders for training and validation\n",
        "train_dataset = ChordDataset(X_train, y_train)\n",
        "val_dataset = ChordDataset(X_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# The train_loader and val_loader are now ready to be used for training and validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWMxDOm0HP1K",
        "outputId": "ba706592-1e65-4ed9-ab69-dab649890090"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "Epoch [1/1], Loss: 3.2473\n",
            "Validation Loss: 3.4490\n",
            "saving model_state_dict\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Assuming the definition of the MusicTransformer model is available from model.py\n",
        "# Initialize the Music Transformer model\n",
        "note_vocab_size = 128  # As specified earlier\n",
        "embed_size = 384  # Example size, adjust as needed\n",
        "num_layers = 6  # Example value, adjust as needed\n",
        "heads = 6  # Example value, adjust as needed\n",
        "device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\")\n",
        "forward_expansion = 4  # Example value, adjust as needed\n",
        "dropout = 0.3 # Example dropout rate, adjust as needed\n",
        "max_length = 100  # Maximum sequence length, adjust as needed\n",
        "epochs=30\n",
        "learning_rate= 0.0001\n",
        "\n",
        "\n",
        "model = MusicTransformer(\n",
        "    note_vocab_size,\n",
        "    embed_size,\n",
        "    num_layers,\n",
        "    heads,\n",
        "    device,\n",
        "    forward_expansion,\n",
        "    dropout,\n",
        "    max_length\n",
        ").to(device)\n",
        "\n",
        "\n",
        "# for name, param in model.named_parameters():\n",
        "#   print(f\"{name}: {param.size()}\")\n",
        "\n",
        "# Loss Function and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n",
        "\n",
        "# Training Loop\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=1):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Extract data and move tensors to the appropriate device\n",
        "            input_data = batch['sequence'].to(device)\n",
        "            targets = batch['label'].to(device)\n",
        "            # Ensure the tensor is of integer type\n",
        "            targets = targets.long()  # Convert to long if not already an integer type\n",
        "\n",
        "\n",
        "            # Select the appropriate column for one-hot encoding\n",
        "            # Adjust this based on your data's structure\n",
        "\n",
        "            one_hot_col1 = F.one_hot(targets[:, 0], num_classes=128)\n",
        "            one_hot_col2 = F.one_hot(targets[:, 1], num_classes=128)\n",
        "\n",
        "            # Concatenate along the last dimension\n",
        "            one_hot_combined = torch.cat((one_hot_col1, one_hot_col2), dim=-1)\n",
        "\n",
        "            one_hot_final = one_hot_combined[:, :128]\n",
        "            # Check if indices are in the valid range\n",
        "\n",
        "            outputs = model(input_data, None)  # Assuming no mask for simplicity\n",
        "            # out1, out2 = outputs.split();\n",
        "            loss = criterion(outputs, one_hot_final.float())\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "        # Validation Loop\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                input_data = batch['sequence'].to(device)\n",
        "                targets = batch['label'].to(device)\n",
        "                targets = targets.long()\n",
        "                one_hot_col1 = F.one_hot(targets[:, 0], num_classes=128)\n",
        "                one_hot_col2 = F.one_hot(targets[:, 1], num_classes=128)\n",
        "\n",
        "                # Concatenate along the last dimension\n",
        "                one_hot_combined = torch.cat((one_hot_col1, one_hot_col2), dim=-1)\n",
        "\n",
        "                one_hot_final = one_hot_combined[:, :128]\n",
        "\n",
        "                outputs = model(input_data, None)\n",
        "                val_loss = criterion(outputs, one_hot_final.float())\n",
        "\n",
        "                # Here, you can also calculate accuracy or other metrics as needed\n",
        "\n",
        "        print(f\"Validation Loss: {val_loss.item():.4f}\")\n",
        "\n",
        "    # Save the model\n",
        "    print('saving model_state_dict')\n",
        "\n",
        "    hyperparameters = {\n",
        "      'learning_rate': learning_rate,\n",
        "      'batch_size': batch_size,\n",
        "      'num_epochs': epochs,\n",
        "      'embed_size': embed_size,\n",
        "      'num_layers': num_layers,\n",
        "      'heads': heads,\n",
        "      'forward_expansion': forward_expansion,\n",
        "      'dropout': dropout,\n",
        "      'max_length': max_length,\n",
        "      'note_vocab_size': note_vocab_size,\n",
        "    }\n",
        "\n",
        "    # Combine the model's state dict and the hyperparameters in a single dictionary\n",
        "    save_dict = {\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'hyperparameters': hyperparameters\n",
        "    }\n",
        "\n",
        "\n",
        "    torch.save(save_dict, 'model_state_dict.pth')\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=epochs)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
