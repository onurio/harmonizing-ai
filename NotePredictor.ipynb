{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nhzT_Fm--EYR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/95/0csrhky965x_1zggpg7jfkr00000gn/T/ipykernel_60317/1913194641.py:3: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-KP7nUUCA3Jh"
      },
      "outputs": [],
      "source": [
        "chords = pd.read_csv(\"output_chords.csv\", header=None)\n",
        "# chords.head\n",
        "\n",
        "chords_sorted = chords.apply(lambda x: sorted(x), axis=1)\n",
        "\n",
        "# Drop duplicates to get unique chords\n",
        "# Count the unique chords\n",
        "# vocab_size = len(chords_sorted.drop_duplicates())\n",
        "# print(\"Vocabulary Size (Unique Chords):\", vocab_size)\n",
        "# # vocab is 10950 for /content/output_chords.csv\n",
        "vocab_size = 10950\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Sequences:\n",
            "[[[60 64 67 72  0  0]\n",
            "  [65 69 72 76  0  0]\n",
            "  [65 64 72  0  0  0]\n",
            "  [62  0  0  0  0  0]]]\n",
            "Output Notes:\n",
            "[[60 71 64 69 67]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def create_sequences(df, sequence_length=4, chord_length=6, num_notes_to_select=5, random_seed=42, data_percent=0.01):\n",
        "    input_sequences = []\n",
        "    output_notes = []\n",
        "    random.seed(random_seed)\n",
        "    \n",
        "    # Calculate the number of samples to select\n",
        "    num_samples = int(len(df) * data_percent)\n",
        "    \n",
        "    # Ensure at least one sample is selected\n",
        "    num_samples = max(1, num_samples)\n",
        "    \n",
        "    # Randomly select sample indices\n",
        "    sampled_indices = random.sample(range(len(df) - sequence_length + 1), num_samples)\n",
        "    \n",
        "    for i in sampled_indices:\n",
        "        sequence = df.iloc[i:i + sequence_length].values.tolist()\n",
        "\n",
        "        # The last chord in the sequence\n",
        "        fourth_chord = sequence[-1].copy()\n",
        "\n",
        "        # Count non-zero notes in the chord\n",
        "        non_zero_notes = [note for note in fourth_chord if note != 0]\n",
        "        num_notes_in_chord = len(non_zero_notes)\n",
        "\n",
        "        # Select the appropriate number of notes to output based on the number of notes in the chord\n",
        "        if num_notes_in_chord > 1:\n",
        "            output = random.sample(non_zero_notes, min(num_notes_to_select, num_notes_in_chord - 1))\n",
        "        else:\n",
        "            output = []\n",
        "\n",
        "        # The remaining note to keep in the chord\n",
        "        remaining_note = [note for note in non_zero_notes if note not in output]\n",
        "        if not remaining_note:\n",
        "            remaining_note = [0]\n",
        "\n",
        "        # Ensure the last chord has one remaining note and is padded to chord_length\n",
        "        last_chord = remaining_note + [0] * (chord_length - len(remaining_note))\n",
        "\n",
        "        # The rest of the chords in the sequence remain the same\n",
        "        input_sequence = sequence[:-1]\n",
        "        input_sequence.append(last_chord)\n",
        "\n",
        "        input_sequences.append(input_sequence)\n",
        "        output_notes.append(output + [0] * (num_notes_to_select - len(output)))  # Pad output to ensure fixed length\n",
        "\n",
        "    return np.array(input_sequences), np.array(output_notes)\n",
        "\n",
        "\n",
        "# Example usage\n",
        "data = {\n",
        "    'note1': [60, 62, 60, 65, 65, 60],\n",
        "    'note2': [64, 65, 64, 69, 64, 62],\n",
        "    'note3': [67, 69, 67, 72, 72, 64],\n",
        "    'note4': [0, 0, 72, 76, 0, 67],\n",
        "    'note5': [0, 0, 0, 0, 0, 69],\n",
        "    'note6': [0, 0, 0, 0, 0, 71]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "input_sequences, output_notes = create_sequences(df, sequence_length=4, chord_length=6, num_notes_to_select=5)\n",
        "\n",
        "print(\"Input Sequences:\")\n",
        "print(input_sequences)\n",
        "print(\"Output Notes:\")\n",
        "print(output_notes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5aUD9EwiHDxf"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "\n",
        "batch_size=128\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('output_chords.csv')\n",
        "\n",
        "# Create input-output pairs\n",
        "\n",
        "input_sequences, output_notes = create_sequences(dataset)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(input_sequences, output_notes, test_size=0.2, random_state=42,shuffle=False)\n",
        "\n",
        "\n",
        "class ChordDataset(Dataset):\n",
        "    def __init__(self, sequences, labels):\n",
        "        self.sequences = sequences\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sequence_matrix = self.sequences[idx]\n",
        "        return {\n",
        "            'sequence': torch.tensor(sequence_matrix, dtype=torch.long),\n",
        "            'label': torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "        }\n",
        "\n",
        "# Adjust the create_sequences function if needed to ensure correct formatting\n",
        "\n",
        "\n",
        "# Creating data loaders for training and validation\n",
        "train_dataset = ChordDataset(X_train, y_train)\n",
        "val_dataset = ChordDataset(X_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# The train_loader and val_loader are now ready to be used for training and validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWMxDOm0HP1K",
        "outputId": "ba706592-1e65-4ed9-ab69-dab649890090"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/omrinuri/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 116\u001b[0m\n\u001b[1;32m    113\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(save_dict, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[5], line 61\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, epochs)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Calculate the loss\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, one_hot_final\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m---> 61\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_tensor.py:524\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    516\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    517\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    522\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    523\u001b[0m     )\n\u001b[0;32m--> 524\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Assuming the definition of the MusicTransformer model is available from model.py\n",
        "# Initialize the Music Transformer model\n",
        "note_vocab_size = 1024  # As specified earlier\n",
        "embed_size = 384  # Example size, adjust as needed\n",
        "num_layers = 6  # Example value, adjust as needed\n",
        "heads = 6  # Example value, adjust as needed\n",
        "device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\")\n",
        "forward_expansion = 4  # Example value, adjust as needed\n",
        "dropout = 0.3 # Example dropout rate, adjust as needed\n",
        "max_length = 100  # Maximum sequence length, adjust as needed\n",
        "epochs=30\n",
        "learning_rate= 0.0001\n",
        "\n",
        "from model_v2 import NotePredictor\n",
        "\n",
        "model = NotePredictor(\n",
        "    input_dim=note_vocab_size,\n",
        "    hidden_dim=embed_size,\n",
        "    num_layers=num_layers,\n",
        "    num_heads=heads,\n",
        "    dropout=dropout,\n",
        "    max_length=max_length,\n",
        "    forward_expansion=forward_expansion\n",
        ").to(device)\n",
        "\n",
        "# for name, param in model.named_parameters():\n",
        "#   print(f\"{name}: {param.size()}\")\n",
        "\n",
        "# Loss Function and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n",
        "\n",
        "\n",
        "# Training Loop\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=1):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            input_data = batch['sequence'].to(device)\n",
        "            targets = batch['label'].to(device)\n",
        "            # Ensure the tensor is of integer type\n",
        "            targets = targets.long()  # Convert to long if not already an integer type\n",
        "\n",
        "\n",
        "            batch_size, num_notes_to_select = targets.shape\n",
        "\n",
        "            one_hot_encoded_columns = []\n",
        "            for i in range(num_notes_to_select):\n",
        "                one_hot_encoded_columns.append(F.one_hot(targets[:, i], num_classes=note_vocab_size))\n",
        "\n",
        "            combined = torch.cat(one_hot_encoded_columns, dim=-1)\n",
        "            one_hot_final = combined[:, :128]\n",
        "            outputs = model(input_data)  # Assuming no mask for simplicity\n",
        "\n",
        "            # Calculate the loss\n",
        "            loss = criterion(outputs, one_hot_final.float())\n",
        "            \n",
        "            \n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "        # Validation Loop\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                input_data = batch['sequence'].to(device)\n",
        "                targets = batch['label'].to(device)\n",
        "                targets = targets.long()\n",
        "                \n",
        "                \n",
        "                    \n",
        "                one_hot_encoded_columns = []\n",
        "                for i in range(num_notes_to_select):\n",
        "                    one_hot_encoded_columns.append(F.one_hot(targets[:, i], num_classes=note_vocab_size))\n",
        "\n",
        "                combined = torch.cat(one_hot_encoded_columns, dim=-1)\n",
        "                one_hot_final = combined[:, :128]\n",
        "                outputs = model(input_data)  # Assuming no mask for simplicity\n",
        "\n",
        "\n",
        "                val_loss = criterion(outputs, one_hot_final.float())\n",
        "                # Here, you can also calculate accuracy or other metrics as needed\n",
        "\n",
        "        print(f\"Validation Loss: {val_loss.item():.4f}\")\n",
        "\n",
        "    # Save the model\n",
        "    print('saving model_state_dict')\n",
        "\n",
        "    hyperparameters = {\n",
        "      'learning_rate': learning_rate,\n",
        "      'batch_size': batch_size,\n",
        "      'num_epochs': epochs,\n",
        "      'embed_size': embed_size,\n",
        "      'num_layers': num_layers,\n",
        "      'heads': heads,\n",
        "      'forward_expansion': forward_expansion,\n",
        "      'dropout': dropout,\n",
        "      'max_length': max_length,\n",
        "      'note_vocab_size': note_vocab_size,\n",
        "    }\n",
        "\n",
        "    # Combine the model's state dict and the hyperparameters in a single dictionary\n",
        "    save_dict = {\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'hyperparameters': hyperparameters\n",
        "    }\n",
        "\n",
        "\n",
        "    torch.save(save_dict, 'model_state_dict.pth')\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=epochs)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
